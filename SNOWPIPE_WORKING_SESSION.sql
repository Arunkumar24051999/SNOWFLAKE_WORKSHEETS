USE DATABSE MYDB;

USE SCHEMA MYDB.PUBLIC;

//CREATE A STORAGE INTEGRATION WITH AWS 
CREATE OR REPLACE STORAGE INTEGRATION s3_int1
STORAGE_PROVIDER= S3
TYPE= EXTERNAL_STAGE
ENABLED= true
STORAGE_AWS_ROLE_ARN=  'arn:aws:iam::597088015338:role/aws_s3_snowflake_integration'
STORAGE_ALLOWED_LOCATIONS=('s3://awss3arun/pipes/csv/') 
COMMENT= 'INTEGRATION WITH AWS S3 BUCKETS';

//CREATE FILE FORMAT
CREATE OR REPLACE FILE FORMAT MYDB.FILE_FORMATS.FILE_FORMAT_PIPE
TYPE= CSV
FIELD_DELIMITER= ','
SKIP_HEADER=1 
EMPTY_FIELD_AS_NULL= TRUE;

//CREATE A STAGE TO STORE THE FILES FROM EXTERNAL CLOUD SERVICE PROVIDER
CREATE OR REPLACE STAGE MYDB.EXTERNAL_STAGES.AWS_STG_PIPE
URL= 's3://awss3arun/pipes/csv/'
STORAGE_INTEGRATION= s3_int1
FILE_FORMAT= MYDB.FILE_FORMATS.FILE_FORMAT_PIPE;

//LIST STAGE
LIST @MYDB.EXTERNAL_STAGES.AWS_STG_PIPE;

//CREATE A TABLE TO UPLOAD FILES FROM STAGE
CREATE OR REPLACE TABLE MYDB.PUBLIC.EMPLOYESS_PIPE(
First_Name STRING,
Last_Name  STRING,
Email STRING,
Phone STRING,
Gender STRING,
Age STRING,
Job_Title STRING,
Years_Of_Experience STRING,
Salary STRING,
Department STRING
);

//CREATE A SCHEMA FOR A PIPE
CREATE OR REPLACE SCHEMA PIPE;

//CREATING PIPE USING COPY COMMAND FOR DATA INGESTION
CREATE OR REPLACE PIPE MYDB.PIPE.AWS_PIPES
AUTO_INGEST=TRUE
AS
COPY INTO MYDB.PUBLIC.EMPLOYESS_PIPE 
FROM @MYDB.EXTERNAL_STAGES.AWS_STG_PIPE
PATTERN= '.*employees.*';

desc pipe MYDB.PIPE.AWS_PIPES;

--CREATE EVENT NOTIFICATION CHANNEL IN AWS ->S3->PROPERTIES AND PASTE THE ARN OVER THERE.
-- AFTER SUCCESSFULLY CREATING EVENT NOTIFICATION CHANNEL UPLOAD FILES IN THE FOLDE AND WAIT FOR A MINUTE UNTILL THE SNOWPIPE LOADS THE FILES TO THE DESTINATION TABLES

SELECT * FROM MYDB.PUBLIC.EMPLOYESS_PIPE;

//TO SUSPEND A PIPE 
ALTER PIPE MYDB.PIPE.AWS_PIPES SET PIPE_EXECUTION_PAUSED= FALSE;

SHOW PIPES;

