//ALTERING THE STORAGE INTEGRATION FOR ADDING THE PATH THAT WE CREATED IN S3 FOR FILE LOADING
ALTER STORAGE INTEGRATION s3_int1
SET 
STORAGE_ALLOWED_LOCATIONS= ('s3://awss3arun/pipes/csv/', 's3://awss3arun/unloaded_files');

 //CREATE A FILE FORMAT FOR THE FILES THAT TO BE LOADED
 CREATE OR REPLACE FILE FORMAT MYDB.FILE_FORMATS.OUTPUT_FILE_FORMAT
 TYPE='CSV'
 FIELD_DELIMITER= ','
 SKIP_HEADER=1
 EMPTY_FIELD_AS_NULL= TRUE;

 // CREATE A STAGE THAT POINTS TO EXTERNAL S3 LOCATION
 CREATE OR REPLACE STAGE MYDB.EXTERNAL_STAGES.OUTPUT_STAGE
 URL= 's3://awss3arun/unloaded_files'
 STORAGE_INTEGRATION= s3_int1
 file_format= 'MYDB.FILE_FORMATS.OUTPUT_FILE_FORMAT';

 //NOW COPY THE FILES FROM TABLES TO THE STAGE
 COPY INTO @MYDB.EXTERNAL_STAGES.OUTPUT_STAGE
 FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1000.CUSTOMER;


//LIST THE FILES THAT GOT LOADED TO STAGE 
LIST @MYDB.EXTERNAL_STAGES.OUTPUT_STAGE;


 
// MAX_FILE_SIZE
COPY INTO @MYDB.EXTERNAL_STAGES.OUTPUT_STAGE
 FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1000.CUSTOMER
MAX_FILE_SIZE=2000000;

// Use OVERWRTIE=TRUE
// If we want to overwrite existing file we can set that to TRUE
COPY INTO @MYDB.EXTERNAL_STAGES.OUTPUT_STAGE
 FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1000.CUSTOMER
MAX_FILE_SIZE=2000000
OVERWRITE = TRUE;
 
//Listing files under my s3 bucket
LIST @MYDB.EXTERNAL_STAGES.OUTPUT_STAGE;

//generate single file
COPY INTO @MYDB.EXTERNAL_STAGES.OUTPUT_STAGE
 FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1000.CUSTOMER
SINGLE = TRUE;

//detailed output
COPY INTO @MYDB.EXTERNAL_STAGES.OUTPUT_STAGE
 FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1000.CUSTOMER
DETAILED_OUTPUT = TRUE;
